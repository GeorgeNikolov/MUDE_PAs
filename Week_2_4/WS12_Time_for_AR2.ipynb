{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5f448fc4cefd406ebb8fb9ca53dfd024",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Workshop 12: Time for fun with AR(2)\n",
    "\n",
    "<h1 style=\"position: absolute; display: flex; flex-grow: 0; flex-shrink: 0; flex-direction: row-reverse; top: 60px;right: 30px; margin: 0; border: 0\">\n",
    "    <style>\n",
    "        .markdown {width:100%; position: relative}\n",
    "        article { position: relative }\n",
    "    </style>\n",
    "    <img src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/tu-logo/TU_P1_full-color.png\" style=\"width:100px\"\\>\n",
    "    <img src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/mude-logo/MUDE_Logo-small.png\" style=\"width:100px\"\\>\n",
    "</h1>\n",
    "<h2 style=\"height: 15px\">\n",
    "</h2>\n",
    "\n",
    "*[CEGM1000 MUDE](http://mude.citg.tudelft.nl/): Week 2.4. Wednesday December 6, 2023.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In general we are interested in identifying the components of a time series, to check stationarity, make statistical judgments, and to identify the appropriate functional model and the stochastic model (ARMA process). In this workshop we will generate a synthetic time series, $S_t$ using a second-order auto-regressive random process ((AR(2)).\n",
    "\n",
    "Autoregressive models AR(p) are widely used in time series analysis to understand and predict sequential data points. As a special case, AR(2) process refers to a second-order autoregressive model, where each data point is linearly dependent on its two immediate preceding values. One practical application of AR(2) models involves prediction. In many practical applications, however, in addition to the noise process, there exist also a linear trend in the form of $Y=Ax+\\epsilon$. To implement prediction, we need to calculate two terms: one called the functional part (from the linear model) and one the stochastic model (from the noise process). The objectives of this workshop are to:\n",
    "\n",
    "- generate a noise process of AR(2) with the given parameters $\\beta_1$ and $\\beta_2$.\n",
    "- calculate the normalized autocovariance function (ACF) and power spectral density (PSD), and investigate their interlink.\n",
    "- estimate the AR(2) parameters $\\beta_1$ and $\\beta_2$ for a given noise process AR(2).\n",
    "- predict future values based on the given linear model $Y=Ax+\\epsilon$ and the noise process\n",
    "\n",
    "Considering the model $Y=Ax+\\epsilon$ note the following:\n",
    "- This is conceptually the same, and uses the same notation, as with observation theory topics from Q1, \n",
    "- Our signal of interest is the $Ax$ part\n",
    "- The \"noise\" is $\\epsilon$ and can be broken down into two more components: 1) _stochastic signal_, and 2) random errors\n",
    "- the _stochastic signal_ is our focus of today; in general we use an ARMA model to represent the stochastic signal, and depending on the assumptions, it can take many forms (e.g., AR(1), AR(2), etc; defined by the parameters $p$ and $q$)\n",
    "- The symbol $\\epsilon$ represents the overall noise of the original time series, whereas the symbole $e$ is the random errors (the part that is left after we take out the stochastic signal from the noise of the original time series using an ARMA process).\n",
    "\n",
    "In this notebook specifically, we will complete the following tasks:\n",
    "1. Generate the time series, then evaluate stationarity and variance\n",
    "2. Evaluate auto-regressive characteristics with ACF and PSD\n",
    "3. Estimate prameters of AR(2) model\n",
    "4. Use model to make a prediction (using BLUE)\n",
    "\n",
    "For each Task, there will be two parts: part a focuses on the implementation of the method in the code, and part b reflects on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from statsmodels.graphics.tsaplots import plot_acf  \n",
    "from scipy.stats import norm\n",
    "from scipy.stats.distributions import chi2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "24e525319d2d49bcaf27de4aaa59d220",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Generate Time Series\n",
    "We intend to simulate (as a time series) 1000 samples at 1-day intervals (so $t=1,...,m$ with $m=1000$ days).\n",
    "\n",
    "_Note: the convention for Time Series and Observation Theory is to use symbole $m$ for the number of samples; however, the symbol $N$ is used in Signal Processing, so in this case $m=N$._\n",
    "\n",
    "The simulated data is based on a second-order auto-regressive AR(2) random process $S_t$ as follows:\n",
    "$$\n",
    "S_t= \\beta_1 S_{t-1}+\\beta_2 S_{t-2}+e_t\n",
    "$$\n",
    "with $t = 1, â€¦, 1000$. The AR(2) process is a stationary time series with a constant mean $\\mu$ and the variance $\\sigma^2$. We set them as follows:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(S_t)=0 \\text{,} \\hspace{2mm} \\mathbb{D}(S_t)=\\sigma^2=2.\n",
    "$$ \n",
    "\n",
    "The two parameters of AR(2) are $\\beta_1$ and $\\beta_2$, and we will consider 2 scenarios:\n",
    "\n",
    "1. Scenario 1: $\\beta_1=0.65$ and $\\beta_2=0.30$ (colored noise)\n",
    "2. Scenario 2: $\\beta_1=\\beta_2=0$ (white noise)\n",
    "\n",
    "The variance of the purely random noise (white noise) $\\epsilon_t$ is $\\sigma^2_e$, which for AR(2), is obtained from the following equation:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\epsilon}^2 = \\frac{(1+\\beta_2)(1-\\beta_1-\\beta_2)(1+\\beta_1-\\beta_2)}{1-\\beta_2} \\sigma^2\n",
    "$$\n",
    "\n",
    "To simulate the data of the AR(2) process, you can make use of a normal distribution; however, _as the realizations of the time series are correlated with each other, we can no longer take random samples from the distribution directly!_ To properly take into account autocorrelation, you will use the above recursive form, which needs initialization. To initialize the first and second data, <code>S[0]=np.random.normal(...)</code> and <code>S[1] = np.random.normal(...)</code> using the normal distribution. You can find information on <code>np.random.normal()</code> [here](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal). To use the above recursive formula you need to simulate $\\epsilon_t$, requiring to have its standard deviation $\\sigma_{\\epsilon}$ of the white noise process (given above).\n",
    "\n",
    "After generating the time series we may compute the mean and variance to see if they are close to their original values\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{m} \\sum_{i=1}^{m} S_i \n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{\\sigma}^2 =\\hat{C}_0 = \\frac{1}{m} \\sum_{i=1}^{m} S_i^2 \n",
    "$$\n",
    "which are unbiased estimates of $\\mu=0$ and $\\sigma^2 =2$, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "48e8df4114544ca4914a15c77372ab30",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 1a:</b>   \n",
    "\n",
    "Complete the code cells below to perform the following analysis:\n",
    "<ol>\n",
    "    <li>Compute the standard deviation $\\sigma_{e}$ based on the provided values for scenario 1. \n",
    "    <li>Simplify the above formula for $\\sigma_{e} $ by taking $\\beta_1=\\beta_2 =0$ (scenario 2).\n",
    "    <li> Simulate the data of the AR(2) process based on the above given values (for the above two scenarios). Plot the simulated data versus time.\n",
    "</ol>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_AR2(beta1,beta2,sigma,m):\n",
    "    sigma_e = YOUR_CODE_HERE\n",
    "    S = np.zeros(m)\n",
    "    S[0] = np.random.normal(loc=0, scale=sigma, size=None)\n",
    "    S[1] = np.random.normal(loc=0, scale=sigma, size=None)\n",
    "    for i in range(2, m):\n",
    "        YOUR_CODE_HERE\n",
    "        \n",
    "    return sigma_e, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "t = np.arange(1, m + 1)\n",
    "# sampling frequency is 1 cycle/day\n",
    "Fs = 1.0\n",
    "# standard deviation of the noise process\n",
    "sigma = np.sqrt(2)          \n",
    "\n",
    "# Scenario 1\n",
    "beta1 = YOUR_CODE_HERE\n",
    "beta2 = YOUR_CODE_HERE\n",
    "\n",
    "sigma_e_1, S1 = gen_AR2(YOUR_CODE_HERE)\n",
    "\n",
    "print(f'Sigma for Scenario 1 is: \\t\\t {sigma:.3f}')\n",
    "print(f'Sigma_e for Scenario 1 is: \\t\\t {sigma_e_1:.3f}')\n",
    "\n",
    "\n",
    "# Create the first plot (Time series data)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, S1, '-', color='blue', label='signal')\n",
    "plt.grid(True)\n",
    "plt.box(True)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('TS data: S1(t)')\n",
    "plt.title('Scenario 1')\n",
    "plt.legend()\n",
    "# compute the mean and variance of the generated time series\n",
    "mu_S1 = np.mean(S1)\n",
    "print(f'The mean of generated S1 process is:\\t {mu_S1:.3f}')\n",
    "sigma_S1 = S1.T@S1/m\n",
    "print(f'The standard deviation of generated S1 process is: {np.sqrt(sigma_S1):.3f}')\n",
    "\n",
    "\n",
    "# Scenario 2\n",
    "beta1 = YOUR_CODE_HERE\n",
    "beta2 = YOUR_CODE_HERE\n",
    "\n",
    "sigma_e_2, S2 = gen_AR2(YOUR_CODE_HERE)\n",
    "\n",
    "print(f'\\nSigma for Scenario 2 is: \\t\\t {sigma:.3f}')\n",
    "print(f'Sigma_e for Scenario 2 is: \\t\\t {sigma_e_2:.3f}')\n",
    "\n",
    "# Create the first plot (Time series data)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, S2, '-', color='blue', label='signal')\n",
    "plt.grid(True)\n",
    "plt.box(True)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('TS data: S2(t)')\n",
    "plt.title('Scenario 2')\n",
    "plt.legend()\n",
    "# compute the mean and variance of the generated time series\n",
    "mu_S2 = np.mean(S2)\n",
    "print(f'The mean of generated S2 process is:\\t {mu_S2:.3f}')\n",
    "sigma_S2 = S2.T@S2/m\n",
    "print(f'The standard deviation of generated S2 process is: {np.sqrt(sigma_S2):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "48e8df4114544ca4914a15c77372ab30",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 1b:</b>   \n",
    "<ol>\n",
    "    <li>Explain your reasoning for expecting a smaller value of $\\sigma_{e}$ compared to $\\sigma$. </li>\n",
    "    <li>Does AR(2) reduce to the white noise process? Compare the $\\sigma_{e}$ of the two processes and with true standard deviation of the two process, i.e. $\\sigma$.</li>\n",
    "    <li>Can you see/explain the two types/levels of time correlations for these two scenarios? </li>\n",
    "    <li>Do the two time series look stationary? Compute the mean and variance of the two processes. Are they comparable with the original values of $\\mu=0$ and $\\sigma^2=2$? Run your Jupyter scripts several times to make more concrete conclusions.</li>\n",
    "</ol>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer in this Markdown cell.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: ACF and PSD\n",
    "The next step is to calculate the normalized autocovariance function (ACF) for the generated time series. The autocovariance function can be estimated from the following equation.\n",
    "$$\n",
    "\\hat{C}_{\\tau} = \\frac{1}{m-\\tau} \\sum_{i=1}^{m-\\tau} (S_i-\\mu_s)(S_{i+\\tau}-\\mu_s)\n",
    "= \\frac{1}{m-\\tau} \\sum_{i=1}^{m-\\tau} S_i\\, S_{i+\\tau}\n",
    "$$\n",
    "The normalized autocovariance function (ACF) can directly be obtained from the auto-covariance function as\n",
    "$$\n",
    "ACF = \\hat{\\rho}_{\\tau} =\\frac{\\hat{C}_{\\tau}}{\\hat{C}_{0}}\n",
    "$$\n",
    "where $\\hat{C}_{0}=\\sigma^2$ is the variance of the process. You can compute the ACF yourself, simply by implementing the above formula in Python. There are however Python commands/functions that can simply produce the ACF (in fact different ways can be employed to compute the ACF in Python). We utilize the functions provided by <code>statsmodels</code>, specifically the <code>plot_acf</code> function. For more information see [here](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html).\n",
    "This command can also have optional parameters like $\\alpha$ (false alarm), for example $\\alpha=0.05$ to make a 95% confidence interval for the computed ACF. \n",
    "\n",
    "On top of that, we also want to take a look at the power spectral density ([PSD](https://mude.citg.tudelft.nl/book/time_series/acf.html#power-spectral-density)). The PSD is the discrete Fourier transform of the ACF. Of course, there are plenty Python functions that will help you compute the PSD. See for example [the example in the MUDE textbook](https://mude.citg.tudelft.nl/book/time_series/exercise4.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 2a:</b>   \n",
    "\n",
    "Complete the code cells below to create a plot of ACF and PSD.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PSD for scenario 1\n",
    "# Plot ACF for the generated process (S1)\n",
    "plot_acf(YOUR_CODE_HERE, lags=100, alpha=0.01, color = 'blue', label='ACF')\n",
    "plt.ylabel('Normalized ACF')\n",
    "plt.xlabel('Lag (day)')\n",
    "plt.title('Normalized ACF')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.box(True)\n",
    "\n",
    "# Calculate and plot power spectral density (PSD) of the generated signal: S1\n",
    "frequencies, psd = signal.periodogram(YOUR_CODE_HERE, fs=Fs, scaling='density', return_onesided=False)\n",
    "# Create the second plot (Power spectral density)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.loglog(frequencies, psd, color='blue', label='PSD')\n",
    "plt.ylabel('Power: PSD')\n",
    "plt.xlabel('Frequency (cycle/day)')\n",
    "plt.title('Power Spectral Density (PSD)')\n",
    "plt.ylim([1e-3, 5e2])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.box(True)\n",
    "\n",
    "# Plot ACF and PSD for scenario 2\n",
    "# Plot ACF for the generated process (S2)\n",
    "plot_acf(YOUR_CODE_HERE, lags=100, alpha=0.01, color = 'blue', label='ACF')\n",
    "plt.ylabel('Normalized ACF')\n",
    "plt.xlabel('Lag (day)')\n",
    "plt.title('Normalized ACF')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.box(True)\n",
    "\n",
    "# Calculate and plot power spectral density (PSD) of the generated signal: S2\n",
    "frequencies, psd = signal.periodogram(YOUR_CODE_HERE, fs=Fs, scaling='density', return_onesided=False)\n",
    "# Create the second plot (Power spectral density)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.loglog(frequencies, psd, color='blue', label='PSD')\n",
    "plt.ylabel('Power: PSD')\n",
    "plt.xlabel('Frequency (cycle/day)')\n",
    "plt.title('Power Spectral Density (PSD)')\n",
    "plt.ylim([1e-3, 5e2])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.box(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 2b:</b>   \n",
    "<ol>\n",
    "    <li>Compare the ACF of the two processes. $S_1$ shows a heavy temporal correlation. Can you explain/link this to the parameters $\\beta_1$, $\\beta_2$ and $\\sigma_{e}$?</li>\n",
    "    <li>Compare the PSD of the two processes. We cannot see any clear 'peak' in either of these PSD. Can you explain it why? Can you explain the slope in the PSD of $S_1$ process?</li>\n",
    "</ol>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer in this Markdown cell.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Estimation of AR(2) parameters\n",
    "Assume that we know the noise process is AR(2), so we know $S_t= \\beta_1 S_{t-1}+\\beta_2 S_{t-2}+e_t$. However we assume that the two parameters $\\beta_1$ and $\\beta_2$ are unknown, to be estimated. This can be implemented using the provided function <code>AR_estimation(S, p)</code> (see below) for AR(p) in general. The function provides the $\\beta$ parameters, their standard deviations and the standard deviation $\\sigma_{e}$ of $e(t)={e}_t$.\n",
    "\n",
    "The formula in task 1 can be inverted to obtain the variance $\\sigma^2$ of the noise process from $\\sigma^2_{e}$ as follow:\n",
    "$$\n",
    "\\sigma^2 = \\frac{1-\\beta_2}{(1+\\beta_2)(1-\\beta_1-\\beta_2)(1+\\beta_1-\\beta_2)} \\sigma_{e}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3a:</b>   \n",
    "\n",
    "It is required to:\n",
    "<ol>\n",
    "    <li> Estimate $\\beta_1$ and $\\beta_2$, along with their standard deviations, for the two processes $S_1$ and $S_2$. Compare them with the original values in task 1.\n",
    "    <li> Compute the standard deviation $\\sigma_{e}$ for the two processes and compare them with the known vales in task 1.\n",
    "    <li> Compute the standard deviation $\\sigma$ from the parameters $\\beta_1$, $\\beta_2$ and $\\sigma_{e}$ for the two processes $S_1$ and $S_2$.\n",
    "    </ol>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR_estimation(S, p):\n",
    "    \"\"\"\n",
    "    This function computes the AR(p) parameters beta_1,...,beta_p \n",
    "    for an AR(p) process Y (stationary S: for example epsilon hat).\n",
    "    \n",
    "    INPUT:\n",
    "        S: m x 1 observations (time series)\n",
    "        p: order of AR\n",
    "    OUTPUT:\n",
    "        Beta: Parameters Beta\n",
    "        S_Beta: Standard deviation of Beta \n",
    "        Sigma_e: Standard deviation of white noise \n",
    "    \"\"\"\n",
    "    m = len(S)\n",
    "    # make the design matrix\n",
    "    A = np.zeros((m-p, p))\n",
    "    for i in range(1, p+1):\n",
    "        A[:,i-1] = S[p-i:m-i]\n",
    "\n",
    "    # removing the first p data from s\n",
    "    S = S[p:m]\n",
    "    m, p = A.shape\n",
    "\n",
    "    # least squares estimate of Beta\n",
    "    Beta = np.linalg.inv(A.T @ A) @ A.T @ S\n",
    "\n",
    "    # least squares estimate of residuals (white noise)\n",
    "    Ehat = S - A @ Beta\n",
    "\n",
    "    # estimation of variance of data (white noise)\n",
    "    Sig2 = (Ehat.T @ Ehat) / (m - p)\n",
    "\n",
    "    # covariance matrix of Beta\n",
    "    Sigma_Beta = Sig2 * np.linalg.inv(A.T @ A)\n",
    "\n",
    "    # standard deviation of Beta\n",
    "    std_Beta = np.sqrt(np.diag(Sigma_Beta))\n",
    "\n",
    "    # standard deviation of white noise\n",
    "    Sigma_e = np.sqrt(Sig2)\n",
    "    \n",
    "    return Beta, std_Beta, Sigma_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7047abf2b93f427a86e5ea387783d174",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2334,
    "execution_start": 1696691527706,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# AR(2) parameter estimation for S1\n",
    "beta_p1, std_beta_p1, sigma_e_p1 = AR_estimation(YOUR_CODE_HERE)\n",
    "var_p1 = YOUR_CODE_HERE\n",
    "print('Beta1 and Beta2 for S1 process are: ',beta_p1)\n",
    "print('Standard deviations of Beta1 and Beta2 for S1 process are: ',std_beta_p1)\n",
    "print('Standard deviation of e(t) for S1 process is:',sigma_e_p1)\n",
    "print('Standard deviation for S1 process is:',np.sqrt(var_p1))\n",
    "\n",
    "# AR(2) parameter estimation for S2\n",
    "beta_p2, std_beta_p2, sigma_e_p2 = AR_estimation(YOUR_CODE_HERE)\n",
    "var_p2 = YOUR_CODE_HERE\n",
    "print('\\n')\n",
    "print('Beta1 and Beta2 for S2 process are: ',beta_p2)\n",
    "print('Standard deviations of Beta1 and Beta2 for S2 process are: ',std_beta_p2)\n",
    "print('Standard deviation of e(t) for S2 process is:',sigma_e_p2)\n",
    "print('Standard deviation for S2 process is:',np.sqrt(var_p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3b:</b>   \n",
    "Compare the calculated standard deviations with those estimated in task 1. Are they close? \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer in this Markdown cell.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Now that we have information about the noise, we can use this to make a forecast. Read about this in [chapter 4.7](https://mude.citg.tudelft.nl/book/time_series/forecasting.html). \n",
    "We apply a simple prediction model. For that we need the $Y=Ax+\\epsilon$ and $\\Sigma_Y$ and the design matrix of the prediction model $A_p$. For our model, we can generate some data from a linear regression model $y(t)=y_0+r t$, with $y_0=0.1$ and $r=0.002$ (error-free data). The generated data $y$ is then added to the noise process data $S$ (here we only use $S_1$).\n",
    "This will then make the final $m\\times 1$ observation vector $Y_{true}$ as follows:\n",
    "$$\n",
    "Y_{true}= \\begin{bmatrix} Y \\\\ Y_p\\end{bmatrix} = y+S\n",
    "$$\n",
    "\n",
    "In order to show how prediction works, we will use the first $m-1$ entries as the 'observed values' $Y$. The last value we generate will serve as our 'true value' of $Y_p$. This value will be assumed unknown, but we will use it to compare the predicted value $\\hat{Y}_p$ with. \n",
    "\n",
    "The design matrices become:\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & t_1 \\\\ \\vdots & \\vdots \\\\ 1 & t_{m-1} \\end{bmatrix} \\quad \\text{and} \\quad A_p=\\begin{bmatrix} 1 &t_m\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "For simplicity we assume $\\Sigma_Y = \\sigma^2 I_{m-1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0491cc69"
   },
   "source": [
    "<div style=\"background-color:#facb8e; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px; width: 95%\"> <p>Chapter 4.7 and 4.8 are not part of the exam material, but we include this exercise here to help understand the methods used above. It will also help you complete the project on Friday.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 4:</b>   \n",
    "\n",
    "Do the following:\n",
    "<ol>\n",
    "    <li> Establish the observation vector $Y$ and design matrix $A$ based on the description above.\n",
    "    <li> Split $Y$ and $A$ into a new $A$ and $Y$ (for the linear model) and $A_p$ and $Y_p$ (for the prediction model).\n",
    "    <li> Follow the steps in Chapter 4.7 to predict $Y_p$, so $\\hat{Y}_p$. You can first use the function 'AR_estimation(Y, p)' to estimate the AR(2) parameters $\\beta_1$ and $\\beta_2$ for the estimated residuals.\n",
    "    <li> Compare the values $\\hat{Y}_p$ with $Y_p$ and also with the function part of $\\hat{Y}_p$, $\\hat{Y}_{signal}=A_p \\hat{X}$.\n",
    "</ol>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take only AR(2) process\n",
    "S = S1\n",
    "\n",
    "# total number of data\n",
    "m = 1000\n",
    "t = np.arange(1, m + 1)\n",
    "# true value of intercept and rate\n",
    "y0 = 0.1\n",
    "r = 0.002\n",
    "# make the error-free observations\n",
    "y = y0+r*t \n",
    "\n",
    "# final data with noise\n",
    "Y = y+S\n",
    "# true value of prediction, data 1000 (only is used to check the prediction)\n",
    "Yp = Y[m-1]\n",
    "# data of 1-999 is used in Y=Ax+e\n",
    "Y = Y[0:m-1]\n",
    "\n",
    "# design matrix from 1 to 1000 data\n",
    "A = np.ones((m, 2))\n",
    "A[:,1] = t[0:m]\n",
    "# design matrix of data of prediction: 1000\n",
    "Ap = A[m-1,:]\n",
    "# new design matrix with 999 data \n",
    "A = A[0:m-1,:]\n",
    "\n",
    "# make the Sigma_Y for 999 data \n",
    "Sigma_Y = sigma ** 2 * np.eye(m-1)\n",
    "# invert Sigma_Y\n",
    "Sigma_Y_inv = np.linalg.inv(Sigma_Y)\n",
    "\n",
    "# BLUE estimate of x\n",
    "Xhat = np.linalg.inv(A.T @ Sigma_Y_inv @ A) @ A.T @ Sigma_Y_inv @ Y\n",
    "\n",
    "# covariance matrix of xhat\n",
    "Sigma_Xhat = np.linalg.inv(A.T @ Sigma_Y_inv @A)\n",
    "\n",
    "# BLUE estimate of y\n",
    "Yhat = A @ Xhat \n",
    "\n",
    "# BLUE estimate of epsilon (residuals)\n",
    "epsilon = Y - Yhat\n",
    "\n",
    "# functional part\n",
    "Yp_f = Ap@Xhat \n",
    "\n",
    "# stochastic part\n",
    "# we first estimate AR(2) pars\n",
    "beta, std_beta, sigma_e = AR_estimation(epsilon, 2)\n",
    "# stochastic part (one index less as we have now 999 data and not 1000)\n",
    "S_m = YOUR_CODE_HERE # THIS IS THE PREDICTION PART\n",
    "Yphat = Yp_f+S_m\n",
    "\n",
    "print('Yp_f: ', Yp_f,'Yp_n: ',Yp_n)\n",
    "print('Yp: ', Yp, 'Yphat: ', Yphat)\n",
    "\n",
    "t = t[0:m-1]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(t, Y, color='blue', label='Data with noise (Y)')\n",
    "plt.plot(t, Yhat, color='red', label='BLUE estimate of Y ($\\hat{Y}$)')\n",
    "plt.plot(t, epsilon, color='green', label='BLUE estimate of e ($\\hat{e}$)')\n",
    "plt.plot(1000, Yphat, 'ro', label='Predicted value (BLUP)')\n",
    "plt.ylabel('Y(t)')\n",
    "plt.xlabel('Time (day)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.box(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 4b:</b>   \n",
    "\n",
    "Review the plot and determine what effect the ARMA process had on the prediction. Try to be quantitative.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer in this Markdown cell.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of notebook.**\n",
    "<h2 style=\"height: 60px\">\n",
    "</h2>\n",
    "<h3 style=\"position: absolute; display: flex; flex-grow: 0; flex-shrink: 0; flex-direction: row-reverse; bottom: 60px; right: 50px; margin: 0; border: 0\">\n",
    "    <style>\n",
    "        .markdown {width:100%; position: relative}\n",
    "        article { position: relative }\n",
    "    </style>\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n",
    "      <img alt=\"Creative Commons License\" style=\"border-width:; width:88px; height:auto; padding-top:10px\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n",
    "    </a>\n",
    "    <a rel=\"TU Delft\" href=\"https://www.tudelft.nl/en/ceg\">\n",
    "      <img alt=\"TU Delft\" style=\"border-width:0; width:100px; height:auto; padding-bottom:0px\" src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/tu-logo/TU_P1_full-color.png\"/>\n",
    "    </a>\n",
    "    <a rel=\"MUDE\" href=\"http://mude.citg.tudelft.nl/\">\n",
    "      <img alt=\"MUDE\" style=\"border-width:0; width:100px; height:auto; padding-bottom:0px\" src=\"https://gitlab.tudelft.nl/mude/public/-/raw/main/mude-logo/MUDE_Logo-small.png\"/>\n",
    "    </a>\n",
    "    \n",
    "</h3>\n",
    "<span style=\"font-size: 75%\">\n",
    "&copy; Copyright 2023 <a rel=\"MUDE Team\" href=\"https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=65595\">MUDE Teaching Team</a> TU Delft. This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "aa9b740477e34ea98fd2031f67fc974e",
  "deepnote_persisted_session": {
   "createdAt": "2023-10-07T15:30:07.197Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
